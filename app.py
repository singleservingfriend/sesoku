import os
import time
import threading
from collections import deque

import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import requests
import sounddevice as sd
import speech_recognition as sr

from flask import Flask, render_template
from flask_socketio import SocketIO

# -------------------- Flask ve SocketIO AyarlarÄ± --------------------
app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret!'
socketio = SocketIO(app, async_mode='threading')

@app.route('/')
def index():
    return render_template('index.html')

# Fonksiyonlar Ã¼zerinden web arayÃ¼zÃ¼ne mesaj gÃ¶nderme
def emit_speech(text):
    socketio.emit('speech', text)

def emit_sound(text):
    socketio.emit('sound', text)

# -------------------- MODEL, ETÄ°KET ve SES AYARLARI --------------------
MODEL_PATH = "./yamnet_model"
LABELS_PATH = "./yamnet_class_map.csv"

# Modeli yerelden yÃ¼kle, yoksa indir ve kaydet
if os.path.exists(MODEL_PATH):
    print("âœ… Yerel model bulundu, yÃ¼kleniyor...")
    yamnet_model = tf.saved_model.load(MODEL_PATH)
else:
    print("ğŸŒ Model bulunamadÄ±, internetten indiriliyor...")
    yamnet_model = hub.load("https://tfhub.dev/google/yamnet/1")
    print("ğŸ’¾ Model kaydediliyor...")
    tf.saved_model.save(yamnet_model, MODEL_PATH)

# Etiket dosyasÄ±: Yerelde yoksa indir
if not os.path.exists(LABELS_PATH):
    print("ğŸŒ Etiket dosyasÄ± indiriliyor...")
    response = requests.get("https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv")
    with open(LABELS_PATH, "wb") as f:
        f.write(response.content)

# Etiketleri yÃ¼kle (CSV'nin baÅŸlÄ±ÄŸÄ± atlanÄ±yor)
with open(LABELS_PATH, "r", encoding="utf8") as f:
    class_labels = [line.strip().split(",")[2] for line in f.readlines()[1:]]

# Mikrofon ve sliding window parametreleri
RATE = 16000                    # Ã–rnekleme hÄ±zÄ± (16 kHz)
CHUNK = RATE * 2                # Her callbackâ€™te alÄ±nan parÃ§a (2 saniye)
OVERLAP_INTERVAL = 0.5          # Her 0.5 saniyede bir pencere iÅŸlenecek
WINDOW_SIZE = RATE * 2          # Ä°ÅŸlenecek pencere uzunluÄŸu (2 saniye)
audio_buffer = deque(maxlen=RATE * 4)  # Son 4 saniyeyi saklayacak

# EÅŸik deÄŸerler
MIN_CONFIDENCE = 0.3            # Genel sesler iÃ§in minimum gÃ¼ven
MIN_SPEECH_CONFIDENCE = 0.3     # KonuÅŸma iÃ§in daha dÃ¼ÅŸÃ¼k eÅŸik

# KonuÅŸma ile ilgili sÄ±nÄ±flar (CSV'deki etiketlere gÃ¶re)
SPEECH_CLASSES = [
    "KonuÅŸma",
    "Ã‡ocuk konuÅŸmasÄ±, Ã§ocuk konuÅŸuyor",
    "Sohbet",
    "AnlatÄ±m, monolog",
    "Bebek mÄ±rÄ±ltÄ±sÄ±",
    "KonuÅŸma sentezleyici",
]

# GLOBAL BUFFER iÃ§in kilit
buffer_lock = threading.Lock()

# -------------------- YENÄ° KONUÅMA ALGILAMA FONKSÄ°YONU --------------------
def listen_and_transcribe():
    """
    KonuÅŸma olduÄŸu sÃ¼rece dinler, bittikten sonra tek seferde transkribe eder.
    """
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()
    
    print("ğŸ¤ Mikrofon dinlemeye hazÄ±r, konuÅŸabilirsiniz.")
    
    with microphone as source:
        recognizer.adjust_for_ambient_noise(source)  # Ortam gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ algÄ±lar
        while True:
            print("Dinleniyor...")
            try:
                # KonuÅŸma tamamlanana kadar bekle ve kaydet
                audio = recognizer.listen(source, timeout=2, phrase_time_limit=5)
                
                # Google API Ã¼zerinden tanÄ±ma iÅŸlemi
                text = recognizer.recognize_google(audio, language="tr-TR")
                print("âœ… Ã‡eviri:", text)
                emit_speech(text)  # Web arayÃ¼zÃ¼ne gÃ¶nder
                
            except sr.UnknownValueError:
                print("AnlaÅŸÄ±lamayan ses.")
            except sr.WaitTimeoutError:
                print("ğŸ›‘ Sessizlik algÄ±landÄ±, dinleme durduruldu.")
                break
            except sr.RequestError as e:
                print("API hatasÄ±:", e)
                break

# -------------------- SOUND ALGILAMA --------------------
def classify_and_emit_sound(audio_data):
    """
    Audio veriyi YAMNet modeli ile sÄ±nÄ±flandÄ±rÄ±r.
    EÄŸer en yÃ¼ksek skor konuÅŸma deÄŸilse, Sound mesajÄ±nÄ± web arayÃ¼zÃ¼ne gÃ¶nderir.
    """
    audio_data = np.array(audio_data, dtype=np.float32)
    scores, embeddings, spectrogram = yamnet_model(audio_data)
    scores_np = scores.numpy()
    avg_scores = np.mean(scores_np, axis=0)

    top_index = np.argmax(avg_scores)
    top_label = class_labels[top_index].strip().lower()
    max_conf = avg_scores[top_index]

    # EÄŸer konuÅŸma deÄŸilse ve yeterince gÃ¼venliyse, sound mesajÄ± gÃ¶nder
    if top_label not in [s.lower() for s in SPEECH_CLASSES] and max_conf >= MIN_CONFIDENCE:
        if top_label in ["silence", "sessizlik"]:
            return
        emit_sound({"label": top_label, "opacity": float(max_conf)})

# -------------------- SLIDING WINDOW SOUND Ä°ÅLEME --------------------
def sliding_window_processor():
    """Buffer'dan WINDOW_SIZE Ã¶rneÄŸini alÄ±p belirli aralÄ±klarla iÅŸleme koyar."""
    while True:
        time.sleep(OVERLAP_INTERVAL)
        with buffer_lock:
            if len(audio_buffer) >= WINDOW_SIZE:
                window = list(audio_buffer)[-WINDOW_SIZE:]
            else:
                continue
        classify_and_emit_sound(window)

# -------------------- SES BUFFER KAYIT --------------------
def audio_callback(indata, frames, time_info, status):
    """Her Ã§aÄŸrÄ±da alÄ±nan audio verisini global buffer'a ekler."""
    if status:
        print(status)
    samples = indata[:, 0].tolist()
    with buffer_lock:
        audio_buffer.extend(samples)

# -------------------- ARKA PLANDA SES DÄ°NLEME --------------------
def run_audio_stream():
    """Ses kaydÄ±nÄ± baÅŸlatÄ±r ve arka plan threadlerini Ã§alÄ±ÅŸtÄ±rÄ±r."""
    processor_thread = threading.Thread(target=sliding_window_processor, daemon=True)
    processor_thread.start()

    print("ğŸ¤ GerÃ§ek zamanlÄ± ses algÄ±lama baÅŸlÄ±yor...")
    with sd.InputStream(samplerate=RATE, channels=1, callback=audio_callback, blocksize=CHUNK):
        try:
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Dinleme durduruldu.")

# -------------------- ARKA PLANDA KONUÅMA DÄ°NLEME --------------------
def run_speech_recognition():
    """
    Arka planda konuÅŸmayÄ± sÃ¼rekli dinleyen bir iÅŸ parÃ§acÄ±ÄŸÄ± baÅŸlatÄ±r.
    """
    while True:
        listen_and_transcribe()
        time.sleep(1)  # Sessizlik sonrasÄ± 1 saniye bekleyip tekrar baÅŸlat

# -------------------- UYGULAMA BAÅLATMA --------------------
if __name__ == '__main__':
    # KonuÅŸmayÄ± arka planda dinleyen thread baÅŸlat
    speech_thread = threading.Thread(target=run_speech_recognition, daemon=True)
    speech_thread.start()

    # Ses (sound) algÄ±lamayÄ± arka planda baÅŸlat
    audio_thread = threading.Thread(target=run_audio_stream, daemon=True)
    audio_thread.start()
    
    # Flask-SocketIO web sunucusunu baÅŸlat
    socketio.run(app, host='0.0.0.0', port=5000)
